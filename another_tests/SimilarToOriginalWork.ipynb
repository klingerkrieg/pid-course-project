{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "from skimage import exposure\n",
    "import cv2\n",
    "from math import pi\n",
    "\n",
    "path = \"./PHOTOS_MALARIA_VHIR_UPC/fotos_2015_12_01/P_falciparum/Trofozoits/DSCN0083.JPG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original work parameters\n",
    "\n",
    "## Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path,0)\n",
    "\n",
    "#resize\n",
    "img = cv2.resize(img,(640,480))\n",
    "\n",
    "exp = cv2.imread(\"./expected_gauss.png\",0)\n",
    "\n",
    "blur = cv2.GaussianBlur(img,(9,9),0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(15, 10, forward=True)\n",
    "\n",
    "blur_tmp = cv2.resize(blur, (exp.shape[1],exp.shape[0]))\n",
    "\n",
    "ax[0].imshow(blur, cmap='gray')\n",
    "ax[0].title.set_text(\"My blur\")\n",
    "ax[1].imshow(exp, cmap='gray')\n",
    "ax[1].title.set_text(\"Expected blur\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(cv2.subtract(exp,blur_tmp),cmap='hot')\n",
    "plt.title(\"Difference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTSU (Adaptative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp = cv2.imread(\"./expected_otsu.png\")\n",
    "\n",
    "block_size = 81\n",
    "offset = 0.3\n",
    "thresh_params = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV,block_size,offset)\n",
    "mode = \"OTSU Adp block_size=%d offset=%.2f\" % (block_size, offset)\n",
    "\n",
    "block_size = 121\n",
    "offset = 0.0\n",
    "thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV,block_size,offset)\n",
    "mode2 = \"Most Similar conf block_size=%d offset=%.2f \" % (block_size, offset)\n",
    "\n",
    "\n",
    "\n",
    "#erode\n",
    "# kernel = np.ones((7, 7), np.uint8)\n",
    "# thresh = cv2.erode(thresh, kernel)\n",
    "# #dilate\n",
    "# kernel = np.ones((5, 5), np.uint8)\n",
    "# thresh = cv2.dilate(thresh, kernel)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(thresh_params, cmap='gray')\n",
    "ax[0].set_title(mode)\n",
    "ax[1].imshow(thresh, cmap='gray')\n",
    "ax[1].set_title(mode2)\n",
    "ax[2].imshow(exp, cmap='gray')\n",
    "ax[2].set_title('Expected')\n",
    "\n",
    "[x.axis('off') for x in ax]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = thresh_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill holes by contours detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Draw contours\n",
    "thresh_filled = np.zeros((thresh.shape[0], thresh.shape[1]), dtype=np.uint8)\n",
    "color = 255\n",
    "for i in range(len(contours)):\n",
    "    cv2.drawContours(thresh_filled, contours, i, color, -1, cv2.LINE_8, hierarchy, 0)\n",
    "    \n",
    "# Show in a window\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(thresh_filled,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erode\n",
    "# eroded = thresh_out.copy()\n",
    "# kernel = np.ones((35, 35), np.uint8)\n",
    "# for t in range(1):\n",
    "#     eroded = cv2.erode(eroded, kernel)\n",
    "    \n",
    "    \n",
    "#dilate\n",
    "#dilated = eroded.copy()\n",
    "#kernel = np.ones((15, 15), np.uint8)\n",
    "#for t in range(3):\n",
    "#    dilated = cv2.dilate(dilated, kernel)\n",
    "\n",
    "\n",
    "   \n",
    "#fill\n",
    "# thresh_fill = thresh.copy()\n",
    "# h, w = thresh_fill.shape[:2]\n",
    "# mask = np.zeros((h+2, w+2), np.uint8)\n",
    "# cv2.floodFill(thresh_fill, mask, (0,0), 255);\n",
    "# thresh_inv = cv2.bitwise_not(thresh_fill)\n",
    "# thresh_out = thresh | thresh_inv\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(thresh_out, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectedComponents(thresh):\n",
    "    output = cv2.connectedComponentsWithStats(thresh, 4, cv2.CV_32S)\n",
    "    (numLabels, labels, stats, centroids) = output\n",
    "    \n",
    "    # Map component labels to hue val, 0-179 is the hue range in OpenCV\n",
    "    label_hue = np.uint8(179*labels/np.max(labels))\n",
    "    blank_ch = 255*np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "\n",
    "    # Converting cvt to BGR\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # set bg label to black\n",
    "    labeled_img[label_hue==0] = 0\n",
    "\n",
    "    labeled_img_rgb = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2RGB)\n",
    "    return labeled_img_rgb, numLabels, labels, stats, centroids\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_img_rgb, numLabelsTmp, labelsTmp, statsTmp, centroidsTmp = connectedComponents(thresh_filled)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(labeled_img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markCentroids(img, numLabels, stats, centroids, estimate=False, cells=(255,255,255)):\n",
    "\n",
    "    for i in range(1, numLabels):\n",
    "        # extract the connected component statistics and centroid for\n",
    "        # the current label\n",
    "        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "        y = stats[i, cv2.CC_STAT_TOP]\n",
    "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        #get area\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        (cX, cY) = centroids[i]\n",
    "\n",
    "    #     #get perimeter\n",
    "    #     cut = thresh_filled[x:w,y:h]\n",
    "    #     contours,hierarchy = cv2.findContours(cut, 1, 2)\n",
    "\n",
    "    #     if len(contours) > 0:\n",
    "    #         cnt = contours[0]\n",
    "    #         M = cv2.moments(cnt)\n",
    "    #         perimeter = cv2.arcLength(cnt,True)\n",
    "\n",
    "    #         compactness = perimeter**2/4*pi*area\n",
    "\n",
    "\n",
    "        if 500 < area < 1500:\n",
    "            cv2.circle(img, (int(cX), int(cY)), 8, (0,0,0), -1)\n",
    "            cv2.circle(img, (int(cX), int(cY)), 5, cells, -1)\n",
    "        \n",
    "        if 1500 < area and estimate:\n",
    "            est = area//1500\n",
    "            cv2.circle(img, (int(cX)-7, int(cY)), 8, (0,0,0), -1)\n",
    "            cv2.circle(img, (int(cX)-7, int(cY)), 5, cells, -1)\n",
    "            cv2.putText(img, str(est), (int(cX), int(cY)+4), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        .5, (0,0,0), 6, cv2.LINE_AA)\n",
    "            cv2.putText(img, str(est), (int(cX), int(cY)+5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        .5, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), cells, 2)\n",
    " \n",
    "    return img\n",
    "    \n",
    "    \n",
    "marked_label = labeled_img_rgb.copy()\n",
    "marked_label = markCentroids(marked_label,numLabelsTmp, statsTmp, centroidsTmp, estimate=True)\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(marked_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break big groups with erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOthersFromCut(img):\n",
    "    # Connected components with stats.\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "\n",
    "    max_label, max_size = max([(i, stats[i, cv2.CC_STAT_AREA]) for i in range(1, nb_components)], key=lambda x: x[1])\n",
    "    \n",
    "    img2 = np.zeros(output.shape, dtype='uint8')\n",
    "    img2[output == max_label] = 255\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: The limits defined that 500 to 1500 isn't enough, some cells, working with original size of image some cells have 2200 of area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion(src,size):\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * size + 1, 2 * size + 1),\n",
    "                                       (size, size))\n",
    "    return cv2.erode(src, element)\n",
    "    #size -= 2\n",
    "    #element = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * size + 1, 2 * size + 1),\n",
    "    #                                   (size, size))\n",
    "    #return cv2.dilate(src,element)\n",
    "    \n",
    "def dilatation(src,size):\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * size + 1, 2 * size + 1),\n",
    "                                       (size, size))\n",
    "    return cv2.dilate(src, element)\n",
    "\n",
    "\n",
    "def erodeBigGroups(img, numLabels, labels, stats, centroids, size=7):\n",
    "    \n",
    "    img2 = img.copy()\n",
    "\n",
    "    kernel = np.ones((size, size), np.uint8)\n",
    "\n",
    "    for i in range(1, numLabels):\n",
    "        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "        y = stats[i, cv2.CC_STAT_TOP]\n",
    "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        (cX, cY) = centroids[i]\n",
    "\n",
    "        cutY = y - 1 if y > 0 else y\n",
    "        cutX = x - 1 if x > 0 else x\n",
    "        cutXW = x+w+1\n",
    "        cutYH = y+h+1\n",
    "\n",
    "        cut = thresh_filled[cutY:cutYH, cutX:cutXW]\n",
    "        cut = cut.copy()\n",
    "\n",
    "        if 1500 < area:\n",
    "            cut_bk = cut.copy()\n",
    "            cut = removeOthersFromCut(cut)\n",
    "\n",
    "            #remove the group from original image\n",
    "            cell_on_original_size = np.zeros( img.shape ,dtype='uint8')\n",
    "            cell_on_original_size[cutY:cutYH, cutX:cutXW] = cut\n",
    "            img2[ cell_on_original_size == 255 ] = 0\n",
    "\n",
    "            #work on group\n",
    "            #cut = cv2.erode(cut, kernel, iterations=1)\n",
    "            cut = erosion(cut,7)\n",
    "            #cut = erosion(cut,15)\n",
    "            #cut = dilatation(cut,11)\n",
    "\n",
    "            #return the eroded and marked group to original image\n",
    "            cell_on_original_size = np.zeros( img.shape ,dtype='uint8')\n",
    "            cell_on_original_size[cutY:cutYH, cutX:cutXW] = cut\n",
    "            img2 += cell_on_original_size\n",
    "    \n",
    "    return img2\n",
    "\n",
    "\n",
    "\n",
    "broken_components = erodeBigGroups(thresh_filled, numLabelsTmp, labelsTmp, statsTmp, centroidsTmp, size=9)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(broken_components, cmap='gray')\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remark centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_img_rgb2, numLabels, labels, stats, centroids = connectedComponents(broken_components)\n",
    "\n",
    "marked_label = labeled_img_rgb2.copy()\n",
    "marked_label = markCentroids(marked_label, numLabels, stats, centroids, estimate=True)\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(marked_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.asarray([[[0,0,1],[0,1,0],[1,0,3]],\n",
    "#      [[0,0,2],[0,1,0],[1,0,0]],\n",
    "#      [[0,0,2],[0,0,3],[1,0,3]]])\n",
    "\n",
    "\n",
    "\n",
    "# red, green, blue = A.T # Temporarily unpack the bands for readability\n",
    "\n",
    "# # Replace white with red... (leaves alpha values alone...)\n",
    "# white_areas = (red == 0) & (blue == 0) & (green == 1)\n",
    "# #A[..., :-1][white_areas.T] = (255, 0, 0) # Transpose back needed\n",
    "# A[white_areas.T] = (255, 0, 0)\n",
    "\n",
    "# print(white_areas.T)\n",
    "# print(A)\n",
    "\n",
    "# #d1, d2, d3 = A.shape\n",
    "# #A_r = A.reshape(1,9,3)[0]\n",
    "# #print(A_r)\n",
    "# #np.unique(A_r, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = labeled_img_rgb2.shape\n",
    "reshapedImg = labeled_img_rgb2.reshape(1,shape[0]*shape[1],3)[0]\n",
    "colors = np.unique(reshapedImg, axis=0)\n",
    "colors = np.delete(colors,0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_color():\n",
    "    color = tuple(np.random.randint(256, size=3))\n",
    "    if (color[0] < 100 and color[1] < 100 and color[2] < 100):\n",
    "        return random_color()\n",
    "    elif (color[0] > 230 and color[1] > 230 and color[2] > 230):\n",
    "        return random_color()\n",
    "    else:\n",
    "        return color\n",
    "\n",
    "labeled_img_rgb3 = labeled_img_rgb2.copy()\n",
    "\n",
    "for color in colors:\n",
    "    newColor = random_color()\n",
    "\n",
    "    red, green, blue = labeled_img_rgb3.T \n",
    "    selected_color = (red == color[0]) & (green == color[1]) & (blue == color[2])\n",
    "    labeled_img_rgb3[selected_color.T] = newColor\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(labeled_img_rgb3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSV Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path)\n",
    "img = cv2.resize(img,(640,480))\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "mask = cv2.inRange(hsv, (110, 0, 0), (150, 255,255))\n",
    "\n",
    "#erode\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "mask = cv2.erode(mask, kernel)\n",
    "#dilate\n",
    "kernel = np.ones((15, 15), np.uint8)\n",
    "mask = cv2.dilate(mask, kernel)\n",
    "\n",
    "par_labeled_rgb, par_numLabels, par_labels, par_stats, par_centroids = connectedComponents(mask)\n",
    "\n",
    "plt.imshow(mask,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "marked = cv2.imread(path)\n",
    "marked = cv2.resize(marked,(640,480))\n",
    "marked_label = labeled_img_rgb3.copy()\n",
    "\n",
    "#MARK CELLS\n",
    "marked = markCentroids(marked, numLabels, stats, centroids, estimate=True, cells=(0,0,255))\n",
    "marked_label = markCentroids(marked_label, numLabels, stats, centroids, estimate=True)\n",
    "        \n",
    "#MARK PARASITES\n",
    "for i in range(1, par_numLabels):\n",
    "    area = par_stats[i, cv2.CC_STAT_AREA]\n",
    "    (cX, cY) = par_centroids[i]\n",
    "    \n",
    "    cv2.circle(marked, (int(cX), int(cY)), 4, (0, 0, 0), -1)\n",
    "    cv2.circle(marked, (int(cX), int(cY)), 3, (0, 220, 240), -1)\n",
    "    \n",
    "    cv2.circle(marked_label, (int(cX), int(cY)), 4, (0, 0, 0), -1)\n",
    "    cv2.circle(marked_label, (int(cX), int(cY)), 3, (240, 220, 0), -1)\n",
    "        \n",
    "    \n",
    "fig, axes = plt.subplots(ncols=2, figsize=(20, 20))\n",
    "ax = axes\n",
    "\n",
    "expR = cv2.imread(\"./expected_result.png\")\n",
    "\n",
    "\n",
    "ax[0].imshow(cv2.cvtColor(marked, cv2.COLOR_BGR2RGB))\n",
    "ax[1].imshow(cv2.cvtColor(expR, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(marked_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
